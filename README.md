### The sections are as follows:
- [Large Language Model](#Large-Language-Model)
- [In-context Learning](#In-context-Learning)
- [Text Embeddings](#Text-Embeddings)


## Large Language Model
### 2023
- ICML [Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling](https://arxiv.org/abs/2304.01373) [[Code]](https://github.com/EleutherAI/pythia)


## In-context Learning
### 2023
- ICML [Compositional Exemplars for In-context Learning](https://arxiv.org/abs/2302.05698)


## Text Embeddings

### 2023
- ACL [One Embedder, Any Task: Instruction-Finetuned Text Embeddings](https://arxiv.org/abs/2212.09741)
- OpenAI [Text and Code Embeddings by Contrastive Pre-Training](https://cdn.openai.com/papers/Text_and_Code_Embeddings_by_Contrastive_Pre_Training.pdf)

### 2022
- arXiv [Text Embeddings by Weakly-Supervised Contrastive Pre-training](https://arxiv.org/abs/2212.03533)
